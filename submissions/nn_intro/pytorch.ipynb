{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to PyTorch\n",
    "\n",
    "[PyTorch](https://pytorch.org/tutorials/) is a leading open-source deep learning framework developed by Meta AI. It's favored by researchers and developers across various machine learning domains, including image recognition, NLP, and reinforcement learning, thanks to its flexibility and ease of use. Its dynamic nature allows for agile experimentation and debugging, catering to both beginners and experts in deep learning.\n",
    "\n",
    "This notebook will be a short introduction to using PyTorch on a simple computer vision task - figuring out the digit in an image using the [MNIST Digit Dataset](https://en.wikipedia.org/wiki/MNIST_database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch defines two major objects for loading data from file:\n",
    "- [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) represents a collection of data to use in training deep learning models.  These work similar to a Python list, but can be customized extensively for better performance.\n",
    "- [`DataLoader`](https://pytorch.org/docs/stable/data.html?highlight=data+loader#torch.utils.data.DataLoader) prepares data into batches for training neural networks (using mini-batch stochastic gradient descent), wrapping an input `Dataset` object.\n",
    "\n",
    "In the example below, we use the `datasets` module to create two data loaders - one for our training set and one for our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"private\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"private\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch (especially later on in this project), you can also create a custom dataset object for your own datasets - check out [this](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) link on how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can iterate through a dataset (like a Python list) to get a sense for the images. The data loader supports indexing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for image, label in train_data:\n",
    "    print(f\"Image {index} has shape {image.shape}, corresponding to digit {label}\")\n",
    "    index += 1\n",
    "    if index == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0][0].view(-1,28)) # have to do some reshaping to visualize the image properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Use `plt.imshow` and the `train_dataset` object to visualize the 30th image in the dataset in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the 30th image in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `DataLoader` object to construct a data loader around a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32) # batch into 32 images / labels at a time\n",
    "test_loader = DataLoader(test_data, batch_size=32) # batch into 32 images / labels at a time\n",
    "\n",
    "index = 0\n",
    "for image, label in train_loader:\n",
    "    print(f\"Batch {index} has shape {image.shape}, with corresponding labels of shape {label.shape}\")\n",
    "    index += 1\n",
    "    if index == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch defines the special `nn.Module` class to represent an arbitary neural network! Here is an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): # Net inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor for the neural network.\"\"\"\n",
    "        super(Net, self).__init__()        # Call superclass constructor\n",
    "        self.fc1 = nn.Linear(28 * 28, 128) # Create fully connected layer as an instance variable of Net \n",
    "        self.fc2 = nn.Linear(128, 10)      # Create another fully connected layer. Output = 10 for 10 classes\n",
    "        self.relu = nn.ReLU()              # Activation function for this neural network\n",
    "        self.flatten = nn.Flatten()        # Convert image to flat array\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass for a neural network - predicts labels from input image\"\"\"\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x)) # call the layers like functors to process inputs\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a neural net to be valid for PyTorch it must:\n",
    "- Inherit from `nn.Module` and call the superclass constructor using `super(Net, self).__init__()`\n",
    "- Override the `forward` function and specify how to get predicted labels for some input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a neural network by calling its constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Add a second fully connected layer to the following neural network that has an input of 128 dimensions and an output of 32 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointNet(nn.Module): \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor for the neural network.\"\"\"\n",
    "        super(Net, self).__init__()       \n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = None # TODO: add a new fully connected layer\n",
    "        self.fc2 = nn.Linear(32, 10)      \n",
    "        self.relu = nn.ReLU()        \n",
    "        self.flatten = nn.Flatten()      \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass for a neural network - predicts labels from input image\"\"\"\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x)) \n",
    "        x = None # TODO: Update the forward pass to include the new fully connected layer\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train any neural network, you need to specify the:\n",
    "- loss function - in PyTorch, we can use Cross-Entropy Loss via `nn.CrossEntropyLoss`\n",
    "- optimizer - algorithm for training model. We will use stochastic gradient descent (technically mini-batch SGD) via `torch.optim.SGD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.007) # lr is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we use the following training loop - it is fairly common across PyTorch to use a similar training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20 # Number of epochs to train for\n",
    "losses, accuracies = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()        # reset gradients\n",
    "        outputs = model(X)           # make a prediction using the model\n",
    "        loss = criterion(outputs, y) # compare predictions to ground truth labels\n",
    "        loss.backward()              # calculate gradients\n",
    "        optimizer.step()             # update parameters\n",
    "\n",
    "    losses.append(loss.detach().item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # test performance after each epoch\n",
    "        correct, total = 0, 0\n",
    "        for X, y in test_loader:\n",
    "            outputs = model(X)\n",
    "            _, predicted = torch.max(outputs.data, 1) # get predicted digit\n",
    "            total += len(y)\n",
    "            correct += (predicted == y).sum().item()\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}], Recent Loss: {loss.item():.4f}, Accuracy: {correct / total *100:.2f}%\"\n",
    "        )\n",
    "        accuracies.append(correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the training loss and test accuracy of our neural network change as the model trains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss by Epoch\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Use `plt.plot` and `accuracies` to visualize the test accuracy of the model as it trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the test accuracy of model as it trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our model on the entire testing dataset now we're done training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # test performance after each epoch\n",
    "    correct, total = 0, 0\n",
    "    for image, label in test_data:\n",
    "        outputs = model(image.view(1, 1, 28, 28))\n",
    "        _, predicted = torch.max(outputs.data, 1)  # get predicted digit\n",
    "        total += 1\n",
    "        correct += (predicted.item() == label)\n",
    "    print(f\"Accuracy: {correct / total *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some examples - consider the 5th image in the testing dataset. Our model predicts it to be the digit `4` - not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = test_data[4][0]\n",
    "plt.imshow(image3.view(-1, 28))\n",
    "print(f\"Predicted label: {model(image3).argmax()}, Actual label: {test_data[4][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the 2nd image in the testing dataset. Our model predicts it to be the digit `6`, when its actually `5`! It seems we have some more training to do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = test_data[8][0]\n",
    "plt.imshow(image3.view(-1, 28))\n",
    "print(f\"Predicted label: {model(image3).argmax()}, Actual label: {test_data[8][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You've trained a model using PyTorch from scratch to be pretty good at classifying this dataset. Next week, we'll practice using **convolutional neural networks**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
