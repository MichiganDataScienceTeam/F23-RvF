{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhJ2EDV65T0F"
      },
      "source": [
        "# Basic Dataset Starter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFqQdEy5T0G"
      },
      "source": [
        "This notebook contains very basic starter code for loading the real vs fake faces dataset from file and working with it. You can borrow from this to:\n",
        "- start training new models (for the transfer learning and custom architecture subteams)\n",
        "- analyze and look into the dataset plus implement data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9VtlpWQ5T0G"
      },
      "source": [
        "## Download the data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pj5xLFkiB1fe"
      },
      "outputs": [],
      "source": [
        "!rm -rf real_and_fake_face real_and_fake_face_detection processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zPbushF5T0H",
        "outputId": "41e056ed-90fc-4d4f-8423-66aa97c6611b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " \n",
            " \n",
            " \n",
            "Downloading real-and-fake-face-detection.zip to /content\n",
            " 98% 424M/431M [00:04<00:00, 132MB/s]\n",
            "100% 431M/431M [00:04<00:00, 93.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from subprocess import Popen, PIPE\n",
        "# makes files from your drive accessible\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# TODO - specify path to your API key via google drive\n",
        "api_key_filepath = \"/content/drive/MyDrive/MDST/RvF/kaggle.json\"\n",
        "\n",
        "\n",
        "# Kaggle API Key setup ------------------\n",
        "cmd = \"mkdir /root/.kaggle\"\n",
        "process = Popen(cmd.split(), stdout=PIPE, stderr=PIPE)\n",
        "stdout, stderr = process.communicate()\n",
        "print(stdout.decode(\"utf-8\"), stderr.decode(\"utf-8\"))\n",
        "cmd = f\"cp -f {api_key_filepath} /root/.kaggle/\"\n",
        "process = Popen(cmd.split(), stdout=PIPE, stderr=PIPE)\n",
        "stdout, stderr = process.communicate()\n",
        "print(stdout.decode(\"utf-8\"), stderr.decode(\"utf-8\"))\n",
        "cmd = f\"chmod 600 /root/.kaggle/kaggle.json\"\n",
        "process = Popen(cmd.split(), stdout=PIPE, stderr=PIPE)\n",
        "print(stdout.decode(\"utf-8\"), stderr.decode(\"utf-8\"))\n",
        "# ------------------------------\n",
        "!kaggle datasets download -d ciplab/real-and-fake-face-detection\n",
        "!unzip -q real-and-fake-face-detection.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NedqO4P_5T0I"
      },
      "source": [
        "# Setup PyTorch Data Loading\n",
        "\n",
        "The code in the next cell can be copied into your notebook to load the downloaded data correctly. It does two things:\n",
        "- processes the dataset into a train and test set\n",
        "- creates data loaders for the training and testing data\n",
        "\n",
        "Don't worry about the details, but if you're on the dataset team, you'll want to read carefully through this part to understand how the code works (since you'll be editing this to make your own version of the dataset!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jIoPLbUb62gZ"
      },
      "outputs": [],
      "source": [
        "from imageio.v3 import imread\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from random import random\n",
        "from shutil import copy\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import functional\n",
        "\n",
        "class RealAndFakeFaceProcessor:\n",
        "    def __init__(self, directory, train_test_split = 0.7) -> None:\n",
        "        self.train_test_split = train_test_split\n",
        "\n",
        "        self.train_index = 0\n",
        "        self.test_index = 0\n",
        "\n",
        "        self.src_directory = Path(directory)\n",
        "        self.directory = self.src_directory.parent / \"processed\"\n",
        "\n",
        "        self.tgt_train = self.directory / \"train\"\n",
        "        self.tgt_train.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.tgt_test = self.directory / \"test\"\n",
        "        self.tgt_test.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.index_by_type = {\"index\":[], \"partition\": [], \"type\": [], \"label\": []}\n",
        "        self.__process(\"training_fake\",\"easy\")\n",
        "        self.__process(\"training_fake\",\"mid\")\n",
        "        self.__process(\"training_fake\",\"hard\")\n",
        "        self.__process(\"training_real\",\"real\")\n",
        "\n",
        "        df = pd.DataFrame(self.index_by_type)\n",
        "        df.to_csv(self.directory / \"images.csv\", index=False)\n",
        "\n",
        "\n",
        "    def __add_image_to_record(self, index: int, partition: str, type: str, label: int):\n",
        "        \"\"\"Real - label is 1, Fake - label is 0\"\"\"\n",
        "        self.index_by_type[\"index\"].append(index)\n",
        "        self.index_by_type[\"partition\"].append(partition)\n",
        "        self.index_by_type[\"type\"].append(type)\n",
        "        self.index_by_type[\"label\"].append(label)\n",
        "\n",
        "\n",
        "    def __process(self, subdir: str, type: str) -> None:\n",
        "        src = self.src_directory / subdir\n",
        "        label = 1 if type == \"real\" else 0\n",
        "\n",
        "        for image in src.iterdir():\n",
        "            if image.name.startswith(type):\n",
        "                random_number = random()\n",
        "                if random() > self.train_test_split:\n",
        "                    copy(image.absolute(), self.tgt_test / f\"{self.test_index}.png\")\n",
        "                    self.__add_image_to_record(self.test_index, \"test\", type, label)\n",
        "                    self.test_index += 1\n",
        "                else:\n",
        "                    copy(image.absolute(), self.tgt_train / f\"{self.train_index}.png\")\n",
        "                    self.__add_image_to_record(self.train_index, \"train\", type, label)\n",
        "                    self.train_index += 1\n",
        "\n",
        "class RealAndFakeFaceDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        directory: str,\n",
        "        partition: str =\"train\"\n",
        "    ) -> 'RealAndFakeFaceDataset':\n",
        "        self.partition = partition\n",
        "        if partition not in (\"train\", \"test\"):\n",
        "            raise ValueError(f\"Invalid partition specified - {partition}\")\n",
        "        self.directory = Path(directory)\n",
        "        self.img_directory = self.directory / partition\n",
        "        metadata = pd.read_csv(self.directory / \"images.csv\")\n",
        "        self.metadata = metadata[metadata[\"partition\"] == self.partition]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple[torch.tensor, int]:\n",
        "        filename = self.img_directory / f\"{index}.png\"\n",
        "        label = self.metadata.iloc[index][\"label\"]\n",
        "\n",
        "        image = torch.from_numpy(imread(filename))\n",
        "        image = image.to(torch.float32)\n",
        "        image = image.permute((2,0,1))\n",
        "        image = functional.resize(image, (224, 224), antialias=True)\n",
        "        image /= 255.0\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_type(self, index) -> str:\n",
        "        return self.metadata.iloc[index][\"type\"]\n",
        "\n",
        "processor = RealAndFakeFaceProcessor(\"real_and_fake_face\") # Call this to process the dataset into a train and test set\n",
        "train = RealAndFakeFaceDataset(\"processed\", \"train\")\n",
        "test = RealAndFakeFaceDataset(\"processed\", \"test\")\n",
        "\n",
        "train_loader = DataLoader(train, batch_size = 32, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size = 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M8PIpb_I84d"
      },
      "source": [
        "# Example Usage - Looking at Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNiYfEaPGd7Y"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# getting the first image in the training set\n",
        "index = 0\n",
        "image, label = train[index]\n",
        "print(f\"Image {index} in the training set has type {train.get_type(index)} and is {'fake' if label == 0 else 'real'}\")\n",
        "plt.imshow(image.permute((1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0eCuGv0HVRR"
      },
      "outputs": [],
      "source": [
        "# getting the first image in the testing set\n",
        "index = 0\n",
        "image, label = test[index]\n",
        "print(f\"Image {index} in the testing set has type {test.get_type(index)} and is {'fake' if label == 0 else 'real'}\")\n",
        "plt.imshow(image.permute((1,2,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKkJBd85I-87"
      },
      "source": [
        "# Example Usage - training a basic PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2qS2Zi1FJAtJ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 4, 5, 2)\n",
        "        self.conv2 = torch.nn.Conv2d(4, 8, 3, 1, padding=\"same\")\n",
        "        self.conv3 = torch.nn.Conv2d(8, 8, 3, 1, padding=\"same\")\n",
        "        self.conv4 = torch.nn.Conv2d(8, 8, 3, 1, padding=\"same\")\n",
        "        self.conv5 = torch.nn.Conv2d(8, 8, 3, 1, padding=\"same\")\n",
        "        self.dense1 = torch.nn.Linear(72, 24)\n",
        "        self.dense2 = torch.nn.Linear(24, 2)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2,2)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        conv = [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5]\n",
        "        dense = [self.dense1, self.dense2]\n",
        "\n",
        "        for layer in conv:\n",
        "            torch.nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
        "            torch.nn.init.zeros_(layer.bias)\n",
        "\n",
        "        for layer in dense:\n",
        "            torch.nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
        "            torch.nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.activation(self.conv1(x)))\n",
        "        x = self.pool(self.activation(self.conv2(x)))\n",
        "        x = self.pool(self.activation(self.conv3(x)))\n",
        "        x = self.pool(self.activation(self.conv4(x)))\n",
        "        x = self.pool(self.activation(self.conv5(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.activation(self.dense1(x))\n",
        "        return self.dense2(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def evaluate(model: nn.Module, criterion: Callable, loader: DataLoader, device='cuda') -> tuple[float]:\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0,0\n",
        "        loss = 0.0\n",
        "        for i, (X, y) in enumerate(loader):\n",
        "            outputs = model(X.to(device)).to('cpu')\n",
        "            loss += criterion(outputs, y).item()\n",
        "            _, predicted = torch.max(outputs.data, 1) # get predicted class\n",
        "            total += len(y)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    return correct / total, loss / total"
      ],
      "metadata": {
        "id": "-qMX_H8o2ode"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu' # automatically use gpu if available\n",
        "epochs = 30  # Change Number of epochs\n",
        "train_losses, train_accuracies = [], []\n",
        "test_losses, test_accuracies = [], []\n",
        "model = Net().to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (X, y) in enumerate(tqdm(train_loader)):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_accuracy, train_loss = evaluate(model, criterion, train_loader, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    test_accuracy, test_loss = evaluate(model, criterion, test_loader, device)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}: Loss - (Train {train_loss:.5f}/Test {test_loss:.2f}, \"\n",
        "        f\"Accuracy - (Train {train_accuracy:.5f}/Test {test_accuracy:.2f})\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Zd9ihYs4yucV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}